---
layout: post
title: JHUG meetup March 15th 2017
---

Today, 15th of March, we held our next [JHUG](http://www.jhug.gr/) meetup ([Meetup.com event](https://www.meetup.com/Java-Hellenic-User-Group/events/237755048/)). [Trasys Greece](http://www.trasysinternational.com/trasys-nrb-group/), [who is hiring](http://www.nrbjobs.be/vacancies/vacancy-senior-java-developer-3983951-31.html), invited us to use the presentation room of their new office, and also bought pizza and beverages. We had around 60-70 attendees, including both old and new members.

The first presentation was by Panagiotis Kapralos ([Linkedin](https://www.linkedin.com/in/panagiotis-kapralos-84b0078b)), whose talk was about Code Refactoring. The talk was entry level, but also useful for more experienced software engineers. Panos began with an example of a class with several opportunities for refactoring. Step by step, he refactored the class to a more maintainable piece of code, explaining what caught his eye each time. After this example, he went on with a set of common Refactorings (i.e. extract method, extract variable, consolidate duplicate conditional fragments) and what each means. Then he presented the not-so-obvious relation between refactoring and economics (which you can use to convince your manager you are not losing your time and his budget). Furthermore, he explained that a software engineer should regard refactoring as an opportunity and not a chore, and allocate time for it. Finally, he concluded by reminding that there are cases where refactoring should not be considered (i.e. when the end-of-life of the software is close). You can find the slides [here](https://github.com/JHUG/JHUG-General-Resources/blob/master/presentations/2017/03-March/Refactoring-In-Practice.pdf) and the video [here](https://vimeo.com/208950085).


The second presentation was by George Kalfopoulos, who talked about Microbenchmarking with [JMH](http://openjdk.java.net/projects/code-tools/jmh/), the Java Microbenchmark Harness. George started by explaining why benchmarking is not straightforward because of optimisations that take place in several layers (JDK, JVM, OS, Hardware). These optimisations can give you a false picture of how performant your software is. JMH helps you profile your code with useful metrics (i.e. throughput, average time) in different setups (i.e. single thread, parallel threads) and even JVM initialisation arguments. It takes care of excluding setup tasks and warm-up executions in the results, so that you have a better picture of how your code behaved while actually executing. George reminded that even JMH results should be taken with a grain of salt, because even a minor Java update may have a drastic effect on the produced numbers. You can find the slides [here](https://github.com/JHUG/JHUG-General-Resources/blob/master/presentations/2017/03-March/Microbenchmarking.pdf) and the video [here](https://vimeo.com/208947227).


In the end of the meetup, we gave away 2 copies of [Java testing with Spock](https://www.manning.com/books/java-testing-with-spock), by our own [Kostis Kapelonis](http://codepipes.com/), and 2 free invitations for [Voxxed Days Athens](https://voxxeddays.com/athens/) (May 18th â€“ 20th 2017), which were kindly offered to JHUG by the conference organizers.
